{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f46c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "\n",
    "!pip install gensim nltk matplotlib scikit-learn\n",
    "\n",
    "imprt gensim\n",
    "from gensim.models imprt Word2Vec\n",
    "from nltk.tokenize imprt word_tokenize\n",
    "from nltk.corpus imprt stopwords\n",
    "imprt string\n",
    "imprt matplotlib.pyplot as plt\n",
    "from sklearn.decomposition imprt PCA\n",
    "imprt numpy as np\n",
    "imprt nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "corpus = [\n",
    "    \"The hospital introduced a new robotic-assisted surgery technique.\",\n",
    "    \"Researchers are developing vaccines to prevent infectious diseases.\",\n",
    "    \"Advancements in neuroscience help in understanding brain disorders.\",\n",
    "]\n",
    "\n",
    "def preprocess_corpus(corpus)))\n",
    "    stop_words =set(stopwords.words('english'))\n",
    "    cleaned_corpus= []\n",
    "\n",
    "    for doc in corpus:\n",
    "        tokens =word_tokenize(doc.lower())\n",
    "        tokens= [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "        cleaned_corpus.append(tokens)\n",
    "    return cleaned_corpus\n",
    "\t\n",
    "cleaned_corpus= preprocess_corpus(corpus)\n",
    "\n",
    "model= Word2Vec(sentences=cleaned_corpus, vector_size=50,window=5, min_count=1,sg=1)\n",
    "\n",
    "model.save(\"medical_word2vec.model\")\n",
    "\n",
    "similar_words =model.wv.most_similar(\"patient\",topn=5)\n",
    "print(f\"Words similar to 'patient': {similar_words}\")\n",
    "\n",
    "words =list(model.wv.index_to_key)\n",
    "vectors= np.array([model.wv[word] for word in words])\n",
    "pca =PCA(n_components=2)\n",
    "reduced_vectors= pca.fit_transform(vectors)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, word in enumerate(words)))\n",
    "    plt.scatter(reduced_vectors[i, 0],reduced_vectors[i, 1])\n",
    "    plt.text(reduced_vectors[i, 0],reduced_vectors[i, 1], word,fontsize=6)\n",
    "\n",
    "plt.title(\"Word Embedding Visualization\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
